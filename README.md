# HowTo Generator

Generate How-to guides from markdown with automated screenshots using Playwright.

## Installation

```bash
npm install
npm run build

# For AI-powered selector resolution (optional)
cp .env.example .env
# Edit .env and add your Cloudflare API key and Account ID
```

## Usage

```bash
# Basic usage
npx howto run example-guide.md

# Custom output directory
npx howto run example-guide.md --out my-guides

# Run with visible browser (for debugging)
npx howto run example-guide.md --headful

# Dry run (parse and validate without executing)
npx howto run example-guide.md --dry-run

# Use secrets for sensitive data
npx howto run example-guide.md --secrets secrets.json
```

## Secrets Management

For handling sensitive data like passwords and API tokens, use the secrets system:

### 1. Create a secrets file (e.g., `secrets.json`):

```json
{
  "username": "user@example.com",
  "password": "mySecretPassword",
  "api_token": "sk-abc123xyz789"
}
```

### 2. Use placeholder syntax in your markdown guides:

```yaml
---
title: "Login Guide"
baseUrl: "https://your-app.com"
steps:
  - type: goto
    url: "/login"
  - type: type
    label: "Email"
    value: "{{secret.username}}"
  - type: type
    label: "Password"
    value: "{{secret.password}}"
  - type: click
    label: "Sign In"
---
```

### 3. Run with secrets:

```bash
# For markdown guides
npx howto run guide.md --secrets secrets.json

# For AI-powered prompts  
npx howto prompt "Login to the application" --base-url https://app.com --secrets secrets.json
```

### Security Features:

- **Never sent to LLM**: Secret values are never included in AI prompts
- **Auto-masking**: Screenshots automatically blur secret inputs
- **Auto-injection**: AI planner automatically suggests secret placeholders for common fields (username, password, etc.)
- **Runtime resolution**: Placeholders are resolved to actual values only at execution time

## Guide Format

Create a markdown file with YAML frontmatter:

```yaml
---
title: "Your Guide Title"
baseUrl: "https://your-app.com"
steps:
  - type: goto
    url: "/login"
  - type: type
    label: "Email"
    value: "user@example.com"
  - type: type
    label: "Password"
    value: "password"
    sensitive: true
  - type: click
    label: "Sign In"
  - type: assert
    label: "Dashboard"
outputDir: "dist"
---

# Your Guide Content

Add a placeholder where you want the steps to appear:

<!-- STEPS:AUTOGENERATED -->
```

## Step Types

- `goto`: Navigate to a URL
- `type`: Enter text into a form field  
- `click`: Click on an element
- `assert`: Verify an element is visible
- `assert_page`: Verify you are on the correct page (by URL)
- `tts_start`: Start generating voice narration (async)
- `tts_wait`: Wait for voice generation to complete
- `keypress`: Press a keyboard key (e.g., Escape, Enter, Tab)

### Optional Parameters

- `screenshot: false` - Skip screenshot for this step (default: true)
- `timeout: 15000` - Custom timeout in ms for assert_page steps
- `sensitive: true` - Mask values in screenshots (for passwords)
- `text: "..."` - Text to convert to speech (tts_start only)
- `voice: "FTNCalFNG5bRnkkaP5Ug"` - ElevenLabs voice ID (tts_start only)

### TTS Timing Controls

- `delayMs: 1000` (on `tts_start`) - Delay narration start by N milliseconds in the final video timeline. Useful to let a page settle visually before voice starts.
- `ttsDefaultDelayMs: 800` (frontmatter) - Global default delay applied to all `tts_start` steps when a step doesn’t specify `delayMs`.
- `TTS_DEFAULT_DELAY_MS` (env) - Environment override for the default delay when neither the step nor frontmatter specifies it.
- `TTS_ALIGN_TO_NEXT_TYPING` (env) - If set to a truthy value, aligns a `tts_start` to the next `type` action’s timestamp (with a small preroll) when possible. Defaults to off.

Examples:

```yaml
---
title: "My Guide"
baseUrl: "https://example.com"
recordVideo: true
ttsDefaultDelayMs: 800  # apply to all tts_start unless overridden per-step
steps:
  - type: goto
    url: "/dashboard"
  - type: assert_page
    url: "/dashboard"
    waitMs: 1000
  - type: tts_start
    label: "dashboard_intro"
    text: "Welcome to your dashboard."
    delayMs: 1200  # start narration ~1.2s after the assert_page
  - type: tts_wait
    label: "dashboard_intro"
---
```

### Video Recording

Enable video recording by adding `recordVideo: true` to your frontmatter:

```yaml
---
title: "My Guide"
baseUrl: "https://example.com"
recordVideo: true
steps: [...]
---
```

When enabled, the tool will:
- Record the entire browser session as a video
- Generate TTS audio files for narration
- Combine video and audio using FFmpeg (if available)
- Output a final `guide-video.mp4` with synchronized narration

## Output

The tool generates:
- Updated markdown file with screenshots embedded
- `screenshots/` folder with all captured images
- `guide-log.json` with execution details

## Features

- ✅ Automated screenshot capture
- ✅ Sensitive data masking
- ✅ Flexible element locators (heuristic + AI-powered)
- ✅ AI-powered selector resolution with OpenAI
- ✅ DOM snapshot analysis for robust element finding
- ✅ Text-to-speech generation with ElevenLabs
- ✅ Asynchronous TTS generation for performance
- ✅ Detailed error reporting
- ✅ CLI with multiple options

## AI-Powered Selector Resolution

When traditional heuristic selector methods fail, the tool can use Llama 3.1 via Cloudflare's AI API to analyze the DOM structure and find the correct elements:

1. **DOM Snapshot**: Captures a simplified representation of the page structure
2. **AI Analysis**: Uses Llama 3.1-8B-Instruct-Fast to understand the DOM and find the best selectors
3. **Fallback Strategy**: Provides multiple selector options with confidence ratings
4. **Automatic Retry**: Falls back to AI when traditional methods fail

To enable AI features:
1. Get a Cloudflare API key from https://dash.cloudflare.com/profile/api-tokens
2. Get your Account ID from https://dash.cloudflare.com/ (right sidebar)
3. Add them to your `.env` file:
   ```
   CLOUDFLARE_API_KEY=your_key_here
   CLOUDFLARE_ACCOUNT_ID=your_account_id_here
   ```
4. The tool will automatically use AI when needed
